{% extends 'base.html' %}

{% block title %}Regressions{% endblock %}

{% block content %}
    <h1>Regression Models</h1>
    <p>
        The primary goal of regression modeling is to model  the relationship between independent and 
        dependent variables in a mathematical form, often to predict the dependent variable based on 
        the values of the independent variables or to understand how changes in the predictors impact 
        the outcome. We will examine two commonly used regressions: linear and polynomial regressions.
    </p>
    <p>
        <b>What is a linear regression?</b>
    </p>
    <p> 
        Linear regression is a statistical method used to model the relationship between one dependent 
        variable and one or more independent variables.
    </p>
    <ul>
        <li><b>Simple linear regression:</b> Involves one dependent variable and one independent 
            variable. A straight line models the relationship and the equation for a simple linear
            regression is y = mx + b, where y is the dependent variable, x is the independent variable,
            m is the slope coefficient, and b is the intercept coefficient.</li>
        <li><b>Multiple linear regression:</b> Involves one dependent variable and multiple independent
            variables. The equation for a multiple linear regression is 
            y = a<sub>0</sub> + a<sub>1</sub>x<sub>1</sub> + a<sub>2</sub>x<sub>2</sub> +...+ a<sub>n</sub>x<sub>n</sub>,
            where x<sub>1</sub>, x<sub>2</sub>,..., x<sub>n</sub> are the independent variables and 
            a<sub>1</sub>, a<sub>2</sub>,..., a<sub>n</sub> coefficients represent the 
            contribution of each predictor.</li>
    </ul>
    <img src=static\images\linear_regression.jpeg width="600" height="400" alt="Linear Regression Plot">
    <br>
    <p>
        <b>What is a polynomial regression?</b>
    </p>
    <p>
        Polynomial regression is a type of regression analysis that models the relationship between the
        dependent variable (y) and one independent variable (x) as an nth-degree polynomial.
        It is used when the relationship between the variables is nonlinear, and a straight line (as in 
        linear regression) cannot adequately capture the trend in the data. The equation for a polynomial
        regression is modeled by y = a<sub>0</sub> + a<sub>1</sub>x<sup>1</sup> + a<sub>2</sub>x<sup>2</sup> +...+ a<sub>n</sub>x<sup>n</sup>,
        where y is the dependent variable (response), x is the independent variable (predictor), and 
        a<sub>0</sub>, a<sub>1</sub>, a<sub>2</sub>,..., a<sub>n</sub> are coefficents of the polynomial.
    </p>
    <img src=static\images\polynomial_regression.jpeg width="600" height="400" alt="Polynomial Regression Plot">
    <br>
    <p>
        <b>When should you use linear vs polynomial regression?</b>
    </p>
    <p>Linear Regression:</p>
    <ul>
        <li>When the relationship between variables is linear.</li>
        <li>When simplicity and interpretability are crucial.</li>
        <li>With smaller datasets to avoid overfitting.</li>
        <li>For initial analysis to understand basic trends.</li>
    </ul>
    <p>Polynomial Regression:</p>
    <ul>
        <li>When the relationship between variables is non-linear.</li>
        <li>To capture more complex relationships in large datasets.</li>
        <li>When flexibility is needed to fit a wider range of data shapes.</li>
        <li>With careful consideration of the polynomial degree to avoid overfitting.</li>
    </ul>
    <br>
    <p>
        <b>Evaluating a regression model:</b>
    </p>
    <p>
        When choosing a regression model, you want to evaluate the model's residuals and R2 value
        (Coefficient of Determination) to determine how well the model performs.
    </p>
    <p>
        <b>Residuals:</b> Larger residuals indicate a poor fit between the model and the data, whereas 
        smaller residuals indicate a better fit. Additionally, a residual scatter plot should display random 
        patterns. Non-random patterns (ie. curves and trends) suggest model issues.
    </p>
    <img src=static\images\good_residual.jpeg width="600" height="400" alt="Example of a good residual plot">
    <p>Good residual plot example</p>
    <img src=static\images\bad_residual.jpeg width="600" height="400" alt="Example of a bad residual plot">
    <p>Bad residual plot example (curve/trend in residuals)</p>
    <p>
        <b>R<sup>2</sup> value:</b> R<sup>2</sup> indicates how well a regression model explains the variability of the dependent 
        variable. Higher R2 values typically indicate a better model, but context matters (e.g., in complex
        or noisy data, even a low R2 can be meaningful).
    </p>
    <ul>
        <li><b>R<sup>2</sup>=1:</b> Perfect fit; the model explains all the variability in the data.</li>
        <li><b>R<sup>2</sup>=0:</b> The model explains none of the variability.</li>
        <li><b>Negative R<sup>2</sup>:</b> Indicates the model is worse than a horizontal line (e.g., poor fit or inappropriate model).</li>
    </ul>
    <p>
        Note: Adding more predictors to a model will generally increase R2, even if the predictors are 
        irrelevant. Thus, when R2 is approximately the same for both a linear and polynomial model, it is 
        generally best to use the linear model to avoid overfitting, especially if the residuals are small 
        and random.
    </p>
    <iframe src="/dash_regressions/" style="width:100%; height:600px; border:none;"></iframe>
    <br>
    <h2>Multiple Choice Quiz</h2>
    <div class="quiz">
        <p>
            Say you plot data using a linear regression and polynomial regression model. The linear regression model
            has a R<sup>2</sup> of 0.87 and the polynomial regression model has a R<sup>2</sup> of 0.98. Which model
            should you use for your analysis?
        </p>
        <form id="quizForm">
            <input type="radio" name="option" value="Linear regression model"> Linear regression model<br>
            <input type="radio" name="option" value="Polynomial regression model"> Polynomial regression model<br>
            <input type="radio" name="option" value="I'm not sure"> I'm not sure<br>
            <br>
            <button type="button" onclick="checkAnswer()">Submit</button>
        </form>
        <div class="result" id="result"></div>
    </div>

    <script>
        function checkAnswer() {
            const options = document.getElementsByName('option');
            let selectedAnswer = '';
            for (const option of options) {
                if (option.checked) {
                    selectedAnswer = option.value;
                    break;
                }
            }
            
            const resultDiv = document.getElementById('result');
            if (selectedAnswer === 'Polynomial regression model') {
                resultDiv.textContent = 'Correct! You should use the polynomial regression model for future analysis because it is a better fit for the data than the linear regression model';
                resultDiv.style.color = 'green';
            } else {
                resultDiv.textContent = 'Try again.';
                resultDiv.style.color = 'red';
            }
        }
    </script>
    <br>
    <h1>
        Example Python Script to Run for Yourself!
    </h1>
    <p>
        This Python script calculates the equations and R<sup>2</sup> values for linear and polynomial regression models.
        Feel free to copy and paste it for your own use!
    </p>
    <pre><code class="language-python">
        import numpy as np
        import pandas as pd
        from sklearn.linear_model import LinearRegression
        from sklearn.preprocessing import PolynomialFeatures
        from sklearn.metrics import r2_score
        
        # Example dataset
        data = {
            'X': [1, 2, 3, 4, 5], # Replace with your own data
            'Y': [1.2, 1.9, 3.0, 3.8, 5.1] # Replace with your own data
        }
        df = pd.DataFrame(data)
        
        # Separate features and target
        X = df['X'].values.reshape(-1, 1)  # Feature matrix
        Y = df['Y'].values                 # Target array
        
        # Linear Regression Model
        linear_model = LinearRegression()
        linear_model.fit(X, Y)
        Y_pred_linear = linear_model.predict(X)
        
        # Extract coefficients for the linear regression equation
        linear_slope = linear_model.coef_[0]
        linear_intercept = linear_model.intercept_
        linear_r2 = r2_score(Y, Y_pred_linear)
        linear_equation = f"y = {linear_slope:.2f}x + {linear_intercept:.2f}"
        
        # Polynomial Regression Model
        degree = 2  # You can adjust the degree as needed
        poly_features = PolynomialFeatures(degree=degree)
        X_poly = poly_features.fit_transform(X)
        
        poly_model = LinearRegression()
        poly_model.fit(X_poly, Y)
        Y_pred_poly = poly_model.predict(X_poly)
        
        # Extract coefficients for the polynomial regression equation
        poly_coefficients = poly_model.coef_
        poly_intercept = poly_model.intercept_
        poly_r2 = r2_score(Y, Y_pred_poly)
        
        # Create the polynomial equation as a string
        poly_terms = [f"{poly_coefficients[i]:.2f}x^{i}" if i > 0 else f"{poly_coefficients[i]:.2f}" for i in range(len(poly_coefficients))]
        poly_equation = "y = " + " + ".join(poly_terms)
        
        # Output results
        print("Linear Regression Model:")
        print(f"Equation: {linear_equation}")
        print(f"R^2 Value: {linear_r2:.4f}")
        print("\nPolynomial Regression Model:")
        print(f"Equation: {poly_equation}")
        print(f"R^2 Value: {poly_r2:.4f}")
    </code></pre>
        
{% endblock %}